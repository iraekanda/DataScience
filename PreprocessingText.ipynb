{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreprocessingText.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IN0gSBYcAHx"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-kOCLC2cix8"
      },
      "source": [
        "#tokenizing\n",
        "def tokenizing(text):\n",
        "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", text).lower().split()\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5CsfgM-bsTW"
      },
      "source": [
        "#stopwords removal\n",
        "nltk.download('stopwords')\n",
        "def stopword_remove(text):    \n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    words = ' '.join([word for word in text if word not in stopwords])\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rfDkcMpOmB7"
      },
      "source": [
        "#stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "def stemming(text):    \n",
        "    porter_stemmer = PorterStemmer()\n",
        "    words = text.split()\n",
        "    words = ' '.join([porter_stemmer.stem(word) for word in words])\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dvfLXoTL3eN"
      },
      "source": [
        "# lemmatizing...\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "def lemmatizing(text): \n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", text).lower().split()\n",
        "    words = [wordnet_lemmatizer.lemmatize(word) if word not in stopwords else word for word in words]\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTEe_Rj83uMK"
      },
      "source": [
        "#pemanggilan fungsi\n",
        "\n",
        "teks = tokenizing('CNB is an adaptation of the standard multinomial naive Bayes (MNB) algorithm that is particularly suited for imbalanced data sets')\n",
        "teks = stopword_remove(teks)\n",
        "teks = stemming(teks)\n",
        "lemmatizing(teks)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}